<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
<title>Category: MachineLearning - Emjay&#39;s DailyBlog</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <meta name="description" content="공부한 것, 알게된 것을 기록하는 블로그입니다.">
<meta name="keywords" content="hexo,datascience,datascientist">
<meta property="og:type" content="website">
<meta property="og:title" content="Emjay&#39;s DailyBlog">
<meta property="og:url" content="https://emjayahn.github.io/categories/MachineLearning/index.html">
<meta property="og:site_name" content="Emjay&#39;s DailyBlog">
<meta property="og:description" content="공부한 것, 알게된 것을 기록하는 블로그입니다.">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://emjayahn.github.io/images/og_image.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Emjay&#39;s DailyBlog">
<meta name="twitter:description" content="공부한 것, 알게된 것을 기록하는 블로그입니다.">
<meta name="twitter:image" content="https://emjayahn.github.io/images/og_image.png">





<link rel="alternative" href="/atom.xml" title="Emjay&#39;s DailyBlog" type="application/atom+xml">



<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    

    
    
    
    

    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    

    
    
    


<link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="is-2-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/Emjaybloglogo_edit.png" alt="Emjay&#39;s DailyBlog" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">Home</a>
                
                <a class="navbar-item" href="/archives">Archives</a>
                
                <a class="navbar-item" href="/categories">Categories</a>
                
                <a class="navbar-item" href="/tags">Tags</a>
                
                <a class="navbar-item" href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    
                    <a class="navbar-item" target="_blank" title="Download on GitHub" href="https://github.com/emjayahn">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main"><div class="card">
    <div class="card-content">
        <nav class="breadcrumb" aria-label="breadcrumbs">
        <ul>
            <li><a href="/categories">Categories</a></li>
            
            <li class="is-active"><a href="#" aria-current="page">MachineLearning</a></li>
        </ul>
        </nav>
    </div>
</div>

    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-06-03T03:18:57.000Z">2019-06-03</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    9 minutes read (About 1322 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/06/03/Classification-Metrics/">Classification Metrics</a>
            
        </h1>
        <div class="content">
            <h1 id="Classification-Metrics-분류-성능-지표"><a href="#Classification-Metrics-분류-성능-지표" class="headerlink" title="Classification Metrics: 분류 성능 지표"></a>Classification Metrics: 분류 성능 지표</h1><p>Kaggle Classification 의 Evaluation 에 자주 사용되는 ROC-AUC를 정리해보면서, 이번 기회에 분류모델에서 자주 사용되는 성능지표(Metric)을 간단하게 정리해봅니다. Confusion Matrix 에서 비롯되는 Metric 들은 이를 이미지로 기억하는 것이 효율적입니다.</p>
<h2 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h2><p>confusion matrix  는 해당 데이터의 정답 클래스(y_true) 와 모델의 예측 클래스(y_pred)의 일치 여부를 갯수로 센 표입니다. 주로, 정답 클래스는 행으로(row), 예측 클래스는 열로(columns) 표현합니다. </p>
<p><img src="Untitled-170ac3e3-8259-4e1a-80e5-647b5bd326fd.png" alt=""></p>
<ul>
<li>(정의하기에 따라 다르지만) 일반적으로, class 1 을 positive로, class 0 을 negative 로 표기합니다.</li>
<li>우리가 예측한 클래스를 기준으로 Positive 와 Negative 를 구분합니다.</li>
<li>그리고 정답과 맞았는지, 틀렸는지를 알려주기 위해 True 와 False 를 각각 붙여줍니다.</li>
</ul>
<h2 id="Accuracy-정확도"><a href="#Accuracy-정확도" class="headerlink" title="Accuracy: 정확도"></a>Accuracy: 정확도</h2><ul>
<li>전체 데이터에 대해 맞게 예측한 비율</li>
</ul>
<p>$$\frac{TP+TN}{TP+FN+FP+TN}$$</p>
<h2 id="Precision-정밀도"><a href="#Precision-정밀도" class="headerlink" title="Precision: 정밀도"></a>Precision: 정밀도</h2><ul>
<li>class 1 이라고 예측한 데이터 중, 실제로 class 1 인 데이터의 비율</li>
</ul>
<p>$$\frac{TP}{TP+FP}$$</p>
<p>우리의 모델이 기본적인 decision이 class 0 이라고 생각할 때, class 1 은 특별한 경우를 detect 한 경우 일 것입니다. 이 때 class 1 이라고 알람을 울리는 우리의 모델이 얼마나 세밀하게 class를 구분 할 수 있는지의 정도를 수치화 한 것입니다.</p>
<h2 id="Recall-재현율"><a href="#Recall-재현율" class="headerlink" title="Recall: 재현율"></a>Recall: 재현율</h2><ul>
<li>실제로 class 1 인 데이터 중에 class 1 이라고 예측한 비율</li>
<li>= Sensivity = TPR</li>
</ul>
<p>$$\frac{TP}{TP+FN}$$</p>
<p>제가 기억하는 방식은, 자동차에 결함이 발견되서 recall 이 되어야 하는데 (실제 고장 데이터중) 얼마나 recall 됐는지로 생각합니다. </p>
<h2 id="Fall-out-위양성율"><a href="#Fall-out-위양성율" class="headerlink" title="Fall-out: 위양성율"></a>Fall-out: 위양성율</h2><ul>
<li>실제로 class 1 이 아닌 데이터 중에 class 1이라고 예측한 비율</li>
<li>낮을 수록 좋음</li>
<li>= FPR = 1 - Specificity</li>
<li>Specificity = 1 - Fall out</li>
</ul>
<p>$$\frac{FP}{FP+TN}$$</p>
<p>실제로 양성데이터가 아닌 데이터에 대해서 우리의 모델이 양성이라고 잘못 예측한 비율을 말합니다. 억울한 데이터의 정도를 측정했다고 생각 할 수 있습니다.</p>
<h2 id="각-Metric-간의-상관관계"><a href="#각-Metric-간의-상관관계" class="headerlink" title="각 Metric 간의 상관관계"></a>각 Metric 간의 상관관계</h2><p>우리 모델의 decision function 을 f(x) 라 할 때, 우리는 f(x)의 결과와 threshold (decision point)를 기준으로 class를 구분합니다.</p>
<ul>
<li><p>Recall vs Fall-out : 양의 상관관계</p>
<p>  Recall은 위의 정의에 의하듯이, 실제로 positive  인  클래스에 대해 얼마나 positve 라고 예측했는지의 비율입니다. 우리가 Recall 을 높이기 위해서는 고정되어있는 실제 positive 데이터 수에 대해 예측하는 positive 데이터의 갯수 threshold 를 낮춰 늘리면 됩니다. 이에 반해 threshold 를 낮추게 되면, 실제로 positive 가 아닌 데이터에 대해 positive 라고 예측하는 억울한 데이터가 많아지므로 Fall-out 은 커지게 되고 둘은 양의 상관관계를 갖게 됩니다.</p>
</li>
<li><p>Recall vs Precision : 대략적인 음의 상관관계</p>
<p>  위에 설명한 것처럼 threshold 를 낮춰 우리가 예측하는 positive 클래스의 숫자를 늘리게 되면, recall 은 높아지는 반면, 예측한 positive 데이터 중 실제 positive 데이터의 비율은 작아 질 수 있습니다.</p>
</li>
</ul>
<h2 id="F-beta-score"><a href="#F-beta-score" class="headerlink" title="F-beta score"></a>F-beta score</h2><ul>
<li>precision 과 recall의 가중 조화평균</li>
</ul>
<p>$$(\frac{1}{1+\beta^2}\frac{1}{precision} + \frac{\beta^2}{1+\beta^2}\frac{1}{recall})^{-1}$$</p>
<p>이처럼, 다양한 Metric 에 대해 우리가 초점을 맞추는 것에 따라 모델의 성능은 다르게 바라 볼 수 있습니다. 따라서 모델에 대해 성능을 평가하고 최종 모델을 선택함에 있어, 서로 다른 Metric 을 동시에 비교해야합니다. 이를 위해 precision 과 recall 을 precision 에 beta^2 만큼 가중하여 바라보는 스코어가 F beta score 입니다.</p>
<p>이 중 beta=1 일 때, score 가 우리가 자주 보는 f1 score 입니다.</p>
<p>$$F_1=\frac{2<em>precision</em>recall}{precision+recall}$$</p>
<h2 id="ROC-Curve-Receiver-Operator-Characteristic-Curve"><a href="#ROC-Curve-Receiver-Operator-Characteristic-Curve" class="headerlink" title="ROC Curve: Receiver Operator Characteristic Curve"></a>ROC Curve: Receiver Operator Characteristic Curve</h2><ul>
<li>Recall vs Fallout 의 plot (TPR vs FPR)</li>
</ul>
<p>위의 예시 처럼, 우리가 클래스를 판별하는 기준이 되는 threshold (decision point) 를 올리거나 내리면서, recall 과 fall out 은 바뀌게 됩니다. 이렇게 threshhold 를 변화 해 가면서, recall 과 fall out 을 plotting 한 것이 ROC curve 입니다.</p>
<ul>
<li>sklearn.metrics.roc_curve() 의 documentation</li>
</ul>
<p><img src="Untitled-1f189e32-c453-43c9-8366-559df3f16464.png" alt=""></p>
<h2 id="ROC-AUC-Area-Under-Curve"><a href="#ROC-AUC-Area-Under-Curve" class="headerlink" title="(ROC-)AUC: Area Under Curve"></a>(ROC-)AUC: Area Under Curve</h2><ul>
<li>위에서 그린 ROC Curve 의 넓이를 점수로써 사용하는 것이 AUC 입니다. AUC 의 유의미한 범위는 class 를 50%의 확률로 random 하게 예측한 넓이인 0.5 보다는 클 것이고, 가장 최대의 AUC 의 넓이는 1 일 것이므로 0.5≤AUC≤1 의 범위를 갖는 score 입니다.</li>
</ul>
<p><img src="Untitled-44d5d317-d0ec-4f1a-8aa0-8bdbfe34bd67.png" alt=""></p>
<ul>
<li>ROC 커브와 AUC score 를 보고 모델에 대한 성능을 평가 하기 위해서, ROC 는 같은 Fall out 에 대해 Recall  은 더 높길 바라고, 같은 Recall  에 대해서는, Recall  이 더 작길 바랍니다. 결국, 그래프가 왼쪽 위로 그려지고, AUC 즉 curve  의 넓이는 커지는 것이 더 좋은 성능의 모델이라고 볼 수 있습니다.</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-31T12:07:52.000Z">2019-05-31</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/MachineLearning/Apache-Spark/">Apache Spark</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    14 minutes read (About 2155 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/05/31/SPARK-BASIC-1/">SPARK BASIC 1</a>
            
        </h1>
        <div class="content">
            <h1 id="Apache-Spark-Basic-1"><a href="#Apache-Spark-Basic-1" class="headerlink" title="Apache Spark Basic 1"></a>Apache Spark Basic 1</h1><ul>
<li>SPARK 를 공부하면서 실습 과정을 정리해서 남깁니다.</li>
<li>실습환경<ol>
<li>CentOS</li>
<li>Spark 2.4.3</li>
<li>Hadoop 2.7</li>
</ol>
</li>
</ul>
<h1 id="1-Spark-shell"><a href="#1-Spark-shell" class="headerlink" title="1. Spark-shell"></a>1. Spark-shell</h1><h2 id="1-1-Introduction"><a href="#1-1-Introduction" class="headerlink" title="1-1. Introduction"></a>1-1. Introduction</h2><p>shell의 spark home directory 에서 다음 명령어를 통해 spark shell 을 진입할 수 있습니다.</p>
<pre><code>$ cd /spark_home_directory/
$ ./bin/spark-shell
</code></pre><p><img src="Untitled-d3bd9451-d568-49aa-bf5a-0f6b7bf598d9.png" alt=""></p>
<ul>
<li>sc : spark context</li>
<li>spark : spark session</li>
</ul>
<p>spark context 와 spark session 의 경우, spark shell에 띄우면서 내부적으로 선언된 변수명이다. </p>
<pre><code>$ jps
// jps 명령어를 통해 현재 돌고 있는 spark process 를 확인할 수 있다. 
// spark processor 가 jvm 을 바탕으로 돌기 때문에, jvm 프로세스가 도는 것을 확인하므로써
// 확인 할 수 있는 것이다.
</code></pre><p><a href="http://localhost:4040" target="_blank" rel="noopener">http://localhost:4040</a>, 즉 해당 서버의 ip:4040 포트를 통해서 드라이버에서 제공되는 웹 UI 를 확인할 수 있다. 이 웹 UI 를 통해 현재 작동하는 프로세서와 클러스터들을 관리 할 수 있다.</p>
<h2 id="1-2-RDD"><a href="#1-2-RDD" class="headerlink" title="1-2. RDD"></a>1-2. RDD</h2><p>spark는 data를 처리할 때, RDD 와 Spark SQL 을 통해서 data object 를 생성하고 이를 바탕으로 다양한 pipeline 으로 동작 할 수 있다. RDD 를 처음 접해보는 실습.</p>
<pre><code>//scala shell
val data = 1 to 10000
val distData = sc.parallelize(data)
distData.filter(_ &lt; 10).collect()
</code></pre><ul>
<li><code>data</code> 가 RDD</li>
<li>sc.parallelize의 return 형 역시 parallelize 된 RDD, 즉 distData 도 RDD</li>
<li>마지막 command line 은 10보다 작은 data 에 대해 filtering 하고 각 executor 에서 실행된 자료를 collect()</li>
<li>spark 의 특징은 .collect() 와 같은 action api 가 실행될 때 모든 것이 실행되는 <strong>Lazy Evaluation (RDD)</strong>으로 동작한다.</li>
</ul>
<p>드라이버 웹 UI 를 통해 이를 확인 할 수 있다. 이전 command line 에서는 아무 동작도 일어나지 않다가 collect() action api 수행을 통해 실제로 command들이 수행되는 것을 확인 할 수 있다. local 에서 default 로 동작하기 때문에 2개의 partition 으로 동작하며, 어떤 shuffling 도 일어나지 않았기 때문에 1개의 stage 임을 확인 할 수 있다.</p>
<p><img src="Untitled-a49c2d30-d7d2-43bf-a2d0-7a54ff94d0c6.png" alt=""></p>
<pre><code>// scala shell
// sc.textFile 을 통해 textfile, md 파일등을 읽어드릴 수 있다.
val data = sc.textFile(&quot;file_name&quot;)

// rdd 의 .map api 를 통해서 rdd 의 element 마다 
val distData = data.map(r =&gt; r + &quot;_experiment!!&quot;)

// 앞선 map 이 수행되고, 각 element(data) 갯수를 세개 된다.
distData.count
</code></pre><p>여기서는 .count 가 action api 이므로, .count 가 수행될 때, 앞선 command 들이 수행되게 된다.</p>
<p><code>sc.textFile()</code> 의 경우 ‘\n’, newline 을 기준으로 element 를 RDD 에 담게 된다.</p>
<p><code>RDD.toDebugString</code> 를 통해 해당 RDD 의 Lineage 를 확인 할 수 있다.</p>
<ul>
<li>가장 왼쪽에 있는 | 를 통해 stage 정보 역시 확인 할 수 있다. shuffle 이 일어나게 되면, stage가 바뀌므로, 서로 다른 stage  에 있는 command 의 경우, 다른 indent에 있게 된다.</li>
</ul>
<p><img src="Untitled-62b02b6f-4150-4dcf-8543-655381c951f7.png" alt=""></p>
<p><code>RDD.getNumPartitions</code> 를 통해 해당 RDD의 Partition 갯수 (=Task 의 갯수), 즉 병렬화 수준을 확인 할 수 있다.</p>
<p><img src="Untitled-a773c2aa-c715-4ccb-8b21-66eaaf1e22b3.png" alt=""></p>
<h3 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle!!"></a>Shuffle!!</h3><p>suffle 이 일어나는 경우는 api 마다 다양할 수 있다. 가장 기본적으로, 우리가 default partition 갯수를 변경하므로써 shuffle 이 일어나는 것을 확인 할 수 있다.</p>
<pre><code>val data = sc.textFile(&quot;file_name&quot;)

data.getNumPartitions
// Partition 의 숫자를 확인해보면, default 이므로 2 인 것을 확인 할 수 있다.

val newData = data.repartition(10)

newData.getNumPartitions
// Partition 갯수가 10로 변경된 것을 확인 할 수 있다.

newData.toDebugString
// newData 의 Lineage 를 확인하면, repartition 이 일어나면서 shuffle 이 되고,
// shuffle 로 인해 stage 가 2개가 되는 것을 확인 할 수 있다.(indentation)

newData.count
// action api 를 수행하여 앞선 command 를 모두 수행
</code></pre><p><img src="Untitled-95d981bb-62a7-457f-9378-0b41db4d5b42.png" alt=""></p>
<p>위 command line 에 대한 DAG 를 웹 UI 를 통해 확인하면, 다음과 같이 stage 가 repartition을 기점으로 나누어 지는 것을 확인 할 수 있다.</p>
<p><img src="Untitled-ef367f62-d6f5-47da-9086-cdaa914aa5d7.png" alt=""></p>
<p>총 Partition의 갯수 (Task의 갯수)를 확인해 보면,  default 로 수행된 partition 2 개와, 우리가 설정해준 Partition 의 갯수인 10개를 합하여 12개인 것을 확인 할 수 있다.</p>
<p><img src="Untitled-6bf929e7-3f6d-4f2f-8898-04ca7ba404b6.png" alt=""></p>
<p>여기서 한 스텝을 더 들어가보면, spark 만의 특이한 특징을 확인 할 수 있다.</p>
<pre><code>// 위 코드에 이어서, newData 에 대해
// newData RDD를 collect 해서 cli에 찍는 command 를 수행해보자.
newData.collect.foreach(println)
</code></pre><p>collect api 와 RDD의 element를 print 를 하는 action api 를 수행할 때, 지금까지 공부한 것으로 생각해 보면, text를 읽어서, 2개의 Partition 을 나누고, 다시 10개의 Partition 을 나누는 작업으로 이전의 12 개의 Task 와 다를게 없을 것 같은 느낌이다. 하지만 UI 를 통해 확인해보면, 10개의 Partition 으로 2개가 skipped 되었다고 확인할 수 있다. DAG 에서도, skipped 된 stage에 대해서 회색으로 확인된다.</p>
<p><img src="Untitled-6e461b14-8e34-4edb-91ad-6dd9ba2ba516.png" alt=""></p>
<p><img src="Untitled-85afaaf0-58d6-4533-995d-c5ec919da985.png" alt=""></p>
<p>이는 spark 에서 이 커맨드라인을 수행할 때, process 간 통신이 file 을 기반으로한 통신을 했기 때문이다. 제일 처음 <code>newData</code> 에 대해서 수행 될 때, 첫 stage 에서 shuffle 이 수행 될 때, 해당 파일을 각 executor 에서 shuffle write 을 하고 저장해두었다가, 두번째 stage 에서 shuffle  이 수행 될때, shuffle read 를 하는 방식으로 file을 기반으로 processor 가 통신하게 된다.</p>
<p><img src="Untitled-310cc7d4-4e31-4362-bf74-f0e046a27052.png" alt=""></p>
<p>따라서, spark 가 같은 command line 을 수행하게 되면 미리 shuffle write  된 file 을 읽기만 함으로써 앞선 stage 의 동일한 반복 작업을 수행하지 않게 되는 것이다. UI 를 확인 해보아도, shuffle read 만 수행 되었다. </p>
<p><img src="Untitled-e89e6c5f-89f8-475c-af4a-78c1e3ae8377.png" alt=""></p>
<h3 id="SaveFile"><a href="#SaveFile" class="headerlink" title="SaveFile!!!"></a>SaveFile!!!</h3><p><code>RDD.saveAsTextFile(&quot;directory_name&quot;)</code> api 를 활용하여, 어떤 처리가 끝난 RDD 를 저장할 수 있다. 이 때 주의 할 점은 parameter 에 들어 가는 것이 directory_name 이라는 것이다. 또한 partition 별로 파일이 저장된다. (e.g. 10개의 partition 이라면, 10개의 file이 저장된다.)</p>
<h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache!!!"></a>Cache!!!</h3><p>spark가 자랑하는 가장 큰 특징은, data(RDD) 를 memory에 cache  함으로써 처리의 속도가 매우 빠르다는 점이다. <code>RDD.cache</code> api 를 통해 memory 에 캐시할 수 있다. </p>
<pre><code>// distData RDD 에 이름을 부여
distData.name = &quot;myData&quot;

// cache!
distData.cache

// action : 5 개의 data 를 가져옴
distData.take(5)

// action : collect
distData.collect
</code></pre><p><code>distData.take(5)</code> 까지 한 결과를 UI 에서 cache 를 살펴보면, 다음과 같다.</p>
<p><img src="Untitled-54196c66-b41c-4216-af72-5a70b030b321.png" alt=""></p>
<p>우리가 설정 한 것 처럼, RDD 의 이름이 myData 로 들어간것을 확인 할 수 있고 cache  역시 확인 할 수 있다. 하지만, Cached  된 비율을 확인하면 전체 RDD  에서 50% 만 된 것을 확인 할 수 있다. 반면에, <code>distData.collect</code> action 을 취하게 되면, Fraction Cached  가 100% 가 된 것을 확인 할 수 있다.</p>
<p><img src="Untitled-8f50bedc-ace7-4c09-9450-fb277ee5830b.png" alt=""></p>
<p>이는 우리의 action 에 따라 cache 할 용량이 달라 질 수 있기 때문이다. spark 입장에서 take(5) api 는 전체 RDD 중 5개의 element data 만 가져오면되고, 이 때 2개의 Partition 중 하나의 Partition 만 cache 해도 충분하기 때문에 Fraction Cached가 50%라고 나오는 것이다. 반면 collect api 는 collect 자체가 각 executor 에 있는 data 를 driver 로 모두 가져오는 것이므로 100% cache 하게 된다.</p>
<p><strong>Cache 에서 중요한 것은, 각 executor 의 cache 를 위한 가용 메모리 공간이 해당 Partition의 용량보다 작을 경우, 저장 할 수 있는 용량만큼 저장되는 것이 아니라, 해당 Partition 은 아예 저장이 안되게 된다. 이 점은 Cache를 할 때, Partition 의 용량과 해당 Executor 의 가용 메모리 공간을 미리 파악하여, 설계해야 한다.</strong></p>
<h3 id="Word-Count-예제"><a href="#Word-Count-예제" class="headerlink" title="Word Count 예제!!!"></a>Word Count 예제!!!</h3><p>우리가 데이터 분석을 할 때, 가장 basic 한 방법은 해당 데이터의 갯수를 세어 보는 것이다. 본 예제에서는 텍스트 파일을 읽어, 띄어쓰기를 바탕으로 word token을 나누고, 이를 세어보자.</p>
<p>WordCount 예제는 매우 basic 한 코드이므로, 어떤 로직으로 돌아가는지 완벽한 이해와 코드작성이 필수라고 생각한다.</p>
<pre><code>val originalDataRDD = sc.textFile(&quot;text-file&quot;)
val wordcountRDD = originalDataRDD.flatMap(line =&gt; line.split(&quot; &quot;))
                                        .map(word =&gt; (word, 1)).reduceByKey(_ + _)

wordcountRDD.collect.foreach(println)
</code></pre><ol>
<li>originalDataRDD 에서 text-file을 읽고,</li>
<li>line 마다 띄어쓰기를 기준으로 split 하고 이를 .flatMap 을 통해, flatten 하게 됩니다.</li>
<li>그리고 .map 을 통해 (word, 1) tuple 형태로 mapping 합니다.</li>
<li>.reduceByKey 를 통해 같은 word 에 대해 그 counting 갯수를 더하게 된 것을 RDD 로 return 하게 됩니다.</li>
</ol>

        </div>
        
        
        
    </div>
</div>








    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-06T03:39:33.000Z">2019-05-06</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/MachineLearning/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    5 minutes read (About 746 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/05/06/Basic-Classification-with-Pytorch/">Basic Classification with Pytorch</a>
            
        </h1>
        <div class="content">
            <h1 id="Basic-Classification-with-Pytorch"><a href="#Basic-Classification-with-Pytorch" class="headerlink" title="Basic Classification with Pytorch"></a>Basic Classification with Pytorch</h1><ul>
<li>이번 post 는 pytorch 를 활용해 기초적인 분류 모델링을 해보면서, pytorch에 익숙함을 높이는 것이 목적입니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</span><br><span class="line"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="hljs-string">'retina'</span></span><br></pre></td></tr></table></figure>
<h2 id="1-Binary-Classification"><a href="#1-Binary-Classification" class="headerlink" title="1. Binary Classification"></a>1. Binary Classification</h2><ol>
<li>Modeling</li>
<li>Sigmoid</li>
<li>Loss : Binary Cross Entropy</li>
</ol>
<h3 id="1-1-Generate-Data"><a href="#1-1-Generate-Data" class="headerlink" title="1.1 Generate Data"></a>1.1 Generate Data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># plotting function</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_scatter</span><span class="hljs-params">(W_, xy, labels)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">for</span> k, color <span class="hljs-keyword">in</span> [(<span class="hljs-number">0</span>, <span class="hljs-string">'b'</span>), (<span class="hljs-number">1</span>, <span class="hljs-string">'r'</span>)]:</span><br><span class="line">        idx = labels.flatten() == k</span><br><span class="line">        plt.scatter(xy[idx, <span class="hljs-number">0</span>], xy[idx, <span class="hljs-number">1</span>], c=color)</span><br><span class="line">        </span><br><span class="line">    x1 = np.linspace(<span class="hljs-number">-0.1</span>, <span class="hljs-number">1.1</span>)</span><br><span class="line">    x2 = -W_[<span class="hljs-number">1</span>] / W_[<span class="hljs-number">2</span>] * x1 - W_[<span class="hljs-number">0</span>] / W_[<span class="hljs-number">2</span>]</span><br><span class="line">    plt.plot(x1, x2, <span class="hljs-string">'--k'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Generate data</span></span><br><span class="line"></span><br><span class="line">W = np.array([<span class="hljs-number">-4.</span>/<span class="hljs-number">5</span>, <span class="hljs-number">3.</span>/<span class="hljs-number">4.</span>, <span class="hljs-number">1.0</span>])</span><br><span class="line"></span><br><span class="line">xy = np.random.rand(<span class="hljs-number">30</span>, <span class="hljs-number">2</span>)</span><br><span class="line">labels = np.zeros(len(xy))</span><br><span class="line">labels[W[<span class="hljs-number">0</span>] + W[<span class="hljs-number">1</span>] * xy[:, <span class="hljs-number">0</span>] + W[<span class="hljs-number">2</span>] * xy[:, <span class="hljs-number">1</span>] &gt; <span class="hljs-number">0</span>] = <span class="hljs-number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_scatter(W, xy, labels)</span><br></pre></td></tr></table></figure>
<p><img src="output_6_0.png" alt="png"></p>
<h3 id="1-2-Train-data"><a href="#1-2-Train-data" class="headerlink" title="1.2 Train data"></a>1.2 Train data</h3><ul>
<li>Generate 한 data 로 부터, x 축 값, y 축 값, augmented term 으로 3가지 column 을 만들어 train data 로 만들어 줍니다.</li>
<li>또한 대응 되는 label 도 model 에 적합한 모양으로 바꾸어 줍니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[<span class="hljs-number">1.0</span>, xval, yval] <span class="hljs-keyword">for</span> xval, yval <span class="hljs-keyword">in</span> xy])</span><br><span class="line">y_train = torch.FloatTensor(labels).view(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">print(x_train[:<span class="hljs-number">5</span>])</span><br><span class="line">print(y_train[:<span class="hljs-number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1.0000, 0.0192, 0.6049],
        [1.0000, 0.0485, 0.2529],
        [1.0000, 0.2412, 0.9115],
        [1.0000, 0.9764, 0.1665],
        [1.0000, 0.9021, 0.5825]])
tensor([[0.],
        [0.],
        [1.],
        [1.],
        [1.]])
</code></pre><h3 id="1-3-Modeling"><a href="#1-3-Modeling" class="headerlink" title="1.3 Modeling"></a>1.3 Modeling</h3><ul>
<li>Linear Model 형태와 Sigmoid 함수, Loss function 은 cross entropy 를 활용해 모델링을 합니다.</li>
<li>여기선, 내장되어있는 함수들을 되도록 사용하지 않고, Low level 로 코드를 작성해 보겠습니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Low level modeling</span></span><br><span class="line">parameter_W = torch.FloatTensor([[<span class="hljs-number">-0.5</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">1.8</span>]]).view(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">parameter_W.requires_grad_(<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([parameter_W], lr=<span class="hljs-number">0.01</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    <span class="hljs-comment"># Prediction</span></span><br><span class="line">    y_hat = F.sigmoid(torch.matmul(x_train, parameter_W))</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># Loss function</span></span><br><span class="line">    loss = (-y_train * torch.log(y_hat) - (<span class="hljs-number">1</span> - y_train) * torch.log((<span class="hljs-number">1</span> - y_hat))).sum().mean()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># Backprop &amp; update</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch 1000 -- loss 6.368619441986084
epoch 2000 -- loss 4.5249152183532715
epoch 3000 -- loss 3.654862403869629
epoch 4000 -- loss 3.122910261154175
epoch 5000 -- loss 2.7545464038848877
epoch 6000 -- loss 2.4800000190734863
epoch 7000 -- loss 2.2651939392089844
epoch 8000 -- loss 2.091233253479004
epoch 9000 -- loss 1.9466761350631714
epoch 10000 -- loss 1.8241318464279175
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parameter_W.data.numpy()</span><br></pre></td></tr></table></figure>
<pre><code>array([[-16.748823],
       [ 16.618748],
       [ 17.622692]], dtype=float32)
</code></pre><ul>
<li>아래 그림을 보면, Train이 잘 된 것을 알 수 있습니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_scatter(parameter_W.data.numpy(), xy, labels)</span><br></pre></td></tr></table></figure>
<p><img src="output_13_0.png" alt="png"></p>
<h2 id="2-Multiclass-Classification"><a href="#2-Multiclass-Classification" class="headerlink" title="2. Multiclass Classification"></a>2. Multiclass Classification</h2><h3 id="2-1-Generate-Data"><a href="#2-1-Generate-Data" class="headerlink" title="2.1 Generate Data"></a>2.1 Generate Data</h3><ul>
<li>이번에는 3개의 label 을 가지고 있는 classification 을 Modeling 해 보겠습니다.</li>
<li>또한, High Level 로 pytorch 의 추상 클래스를 이용해 모델링 해보겠습니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_scatter</span><span class="hljs-params">(W1, W2, xy, labels)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">for</span> k, color <span class="hljs-keyword">in</span> [(<span class="hljs-number">0</span>, <span class="hljs-string">'b'</span>), (<span class="hljs-number">1</span>, <span class="hljs-string">'r'</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">'y'</span>)]:</span><br><span class="line">        idx = labels.flatten() == k</span><br><span class="line">        plt.scatter(xy[idx, <span class="hljs-number">0</span>], xy[idx, <span class="hljs-number">1</span>], c=color)</span><br><span class="line">        </span><br><span class="line">    x1 = np.linspace(<span class="hljs-number">-0.6</span>, <span class="hljs-number">1.6</span>)</span><br><span class="line">    x2 = -W1[<span class="hljs-number">1</span>] / W1[<span class="hljs-number">2</span>] * x1 - W1[<span class="hljs-number">0</span>] / W1[<span class="hljs-number">2</span>]</span><br><span class="line">    x3 = -W2[<span class="hljs-number">1</span>] / W2[<span class="hljs-number">2</span>] * x1 - W2[<span class="hljs-number">0</span>] / W2[<span class="hljs-number">2</span>]</span><br><span class="line">    plt.plot(x1, x2, <span class="hljs-string">'--k'</span>)</span><br><span class="line">    plt.plot(x1, x3, <span class="hljs-string">'--k'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Generate data</span></span><br><span class="line"></span><br><span class="line">W1 = np.array([<span class="hljs-number">-1</span>, <span class="hljs-number">3.</span>/<span class="hljs-number">4.</span>, <span class="hljs-number">1.0</span>])</span><br><span class="line">W2 = np.array([<span class="hljs-number">-1.</span>/<span class="hljs-number">5</span>, <span class="hljs-number">3.</span>/<span class="hljs-number">4.</span>, <span class="hljs-number">1.0</span>])</span><br><span class="line"></span><br><span class="line">xy = <span class="hljs-number">2</span> * np.random.rand(<span class="hljs-number">100</span>, <span class="hljs-number">2</span>) - <span class="hljs-number">0.5</span></span><br><span class="line">labels = np.zeros(len(xy))</span><br><span class="line">labels[(W1[<span class="hljs-number">0</span>] + W1[<span class="hljs-number">1</span>] * xy[:, <span class="hljs-number">0</span>] + W1[<span class="hljs-number">2</span>] * xy[:, <span class="hljs-number">1</span>] &gt; <span class="hljs-number">0</span>)] = <span class="hljs-number">1</span></span><br><span class="line">labels[(W2[<span class="hljs-number">0</span>] + W2[<span class="hljs-number">1</span>] * xy[:, <span class="hljs-number">0</span>] + W2[<span class="hljs-number">2</span>] * xy[:, <span class="hljs-number">1</span>] &lt; <span class="hljs-number">0</span>)] = <span class="hljs-number">2</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_scatter(W1, W2, xy, labels)</span><br></pre></td></tr></table></figure>
<p><img src="output_18_0.png" alt="png"></p>
<h3 id="2-2-Train-data"><a href="#2-2-Train-data" class="headerlink" title="2.2 Train data"></a>2.2 Train data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[<span class="hljs-number">1.0</span>, xval, yval] <span class="hljs-keyword">for</span> xval, yval <span class="hljs-keyword">in</span> xy])</span><br><span class="line">y_train = torch.LongTensor(labels)</span><br><span class="line">print(x_train[<span class="hljs-number">-5</span>:])</span><br><span class="line">print(y_train[<span class="hljs-number">-5</span>:])</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[ 1.0000,  0.9641,  1.3851],
        [ 1.0000, -0.4445,  1.0595],
        [ 1.0000,  1.0854, -0.1216],
        [ 1.0000,  0.8707,  0.1640],
        [ 1.0000,  0.7043,  1.3483]])
tensor([1, 0, 0, 0, 1])
</code></pre><h3 id="2-3-Modeling"><a href="#2-3-Modeling" class="headerlink" title="2.3 Modeling"></a>2.3 Modeling</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MultiModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = MultiModel()</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    y_hat = model(x_train)</span><br><span class="line">    </span><br><span class="line">    loss = F.cross_entropy(y_hat, y_train)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch 1000 -- loss 0.6635385155677795
epoch 2000 -- loss 0.5513403415679932
epoch 3000 -- loss 0.4890784025192261
epoch 4000 -- loss 0.44675758481025696
epoch 5000 -- loss 0.4151267111301422
epoch 6000 -- loss 0.39017024636268616
epoch 7000 -- loss 0.369760125875473
epoch 8000 -- loss 0.35262930393218994
epoch 9000 -- loss 0.3379631042480469
epoch 10000 -- loss 0.3252090811729431
</code></pre><h3 id="2-4-Accuracy-계산"><a href="#2-4-Accuracy-계산" class="headerlink" title="2.4 Accuracy 계산"></a>2.4 Accuracy 계산</h3><ul>
<li>Accuracy 가 96 % 로 비교적 잘 분류 된 것을 확인 할 수 있습니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">accuracy = (torch.ByteTensor(model(x_train).max(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == y_train)).sum().item() / len(y_train)</span><br><span class="line">print(<span class="hljs-string">"Accuracy: &#123;&#125;"</span>.format(accuracy))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy: 0.96
</code></pre>
        </div>
        
        
        
    </div>
</div>








    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-04T14:54:06.000Z">2019-05-04</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/MachineLearning/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    7 minutes read (About 1081 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/05/04/Linear-Model-with-Pytorch/">Linear Model with Pytorch</a>
            
        </h1>
        <div class="content">
            <h1 id="Linear-Model-with-Pytorch"><a href="#Linear-Model-with-Pytorch" class="headerlink" title="Linear Model with Pytorch"></a>Linear Model with Pytorch</h1><ul>
<li>이 글의 목적은, 지난 Linear Regression 에서 좀더 나아가서, 다양한 Regression 예제들을 Linear Model (WX) 형태로 pytorch 를 이용해 풀어 보는 것입니다.</li>
<li>Pytorch 를 사용하여 Modeling 과 loss function 등을 class 형태, 내장 loss 함수등을 사용해보겠습니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn</span><br><span class="line"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim</span><br><span class="line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"><span class="hljs-keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="hljs-string">'retina'</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h2 id="1-Quadratic-Regression-Model"><a href="#1-Quadratic-Regression-Model" class="headerlink" title="1. Quadratic Regression Model"></a>1. Quadratic Regression Model</h2><p>$$<br>f(x) = w_0 + w_1x + w_2x^2<br>$$</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="hljs-number">-10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>)</span><br><span class="line">y = x**<span class="hljs-number">2</span> + <span class="hljs-number">0.7</span> * x + <span class="hljs-number">3.0</span> + <span class="hljs-number">20</span> * np.random.rand(len(x))</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_4_0.png" alt="png"></p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[each_x**<span class="hljs-number">2</span>, each_x, <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> each_x <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor(y)</span><br><span class="line"></span><br><span class="line">print(<span class="hljs-string">"x_train shape: "</span>, x_train.shape)</span><br><span class="line">print(<span class="hljs-string">"y_train shape: "</span>, y_train.shape)</span><br></pre></td></tr></table></figure>
<pre><code>x_train shape:  torch.Size([100, 3])
y_train shape:  torch.Size([100])
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">W = torch.zeros(<span class="hljs-number">3</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([W], lr=<span class="hljs-number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = x_train.matmul(W)</span><br><span class="line">    </span><br><span class="line">    loss = torch.mean((hypothesis - y_train) ** <span class="hljs-number">2</span>)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch: 1000 -- Parameters: W: tensor([1.1738, 0.4943, 1.0699]) -- loss 85.30189514160156
epoch: 2000 -- Parameters: W: tensor([1.1581, 0.4949, 2.0311]) -- loss 76.05414581298828
epoch: 3000 -- Parameters: W: tensor([1.1437, 0.4949, 2.9105]) -- loss 68.31205749511719
epoch: 4000 -- Parameters: W: tensor([1.1305, 0.4949, 3.7151]) -- loss 61.83049011230469
epoch: 5000 -- Parameters: W: tensor([1.1185, 0.4949, 4.4514]) -- loss 56.4041862487793
epoch: 6000 -- Parameters: W: tensor([1.1075, 0.4949, 5.1250]) -- loss 51.86140060424805
epoch: 7000 -- Parameters: W: tensor([1.0974, 0.4949, 5.7414]) -- loss 48.058231353759766
epoch: 8000 -- Parameters: W: tensor([1.0882, 0.4949, 6.3054]) -- loss 44.8742790222168
epoch: 9000 -- Parameters: W: tensor([1.0798, 0.4949, 6.8214]) -- loss 42.20869445800781
epoch: 10000 -- Parameters: W: tensor([1.0721, 0.4949, 7.2935]) -- loss 39.97709655761719
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, (x_train.data.matmul(W.data).numpy()), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_7_0.png" alt="png"></p>
<h2 id="2-Cubic-Regression-Model"><a href="#2-Cubic-Regression-Model" class="headerlink" title="2. Cubic Regression Model"></a>2. Cubic Regression Model</h2><p>$$<br>f(x) = w_0 + w_1x + w_2x^2 + w_3x^3<br>$$</p>
<h3 id="2-1-Generate-Toy-data"><a href="#2-1-Generate-Toy-data" class="headerlink" title="2.1 Generate Toy data"></a>2.1 Generate Toy data</h3><ul>
<li>100개의 data 를 생성합니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">100</span>)</span><br><span class="line">y = <span class="hljs-number">3</span>*x**<span class="hljs-number">3</span> - <span class="hljs-number">0.2</span> * x ** <span class="hljs-number">2</span> + <span class="hljs-number">0.7</span> * x + <span class="hljs-number">3</span> + <span class="hljs-number">0.5</span> * np.random.rand(len(x))</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_11_0.png" alt="png"></p>
<h3 id="2-2-Define-Model"><a href="#2-2-Define-Model" class="headerlink" title="2.2 Define Model"></a>2.2 Define Model</h3><ul>
<li>x_train과 y_train 을 만들어줍니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[xval**<span class="hljs-number">3</span>, xval**<span class="hljs-number">2</span>, xval, <span class="hljs-number">1</span>]<span class="hljs-keyword">for</span> xval <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor([y]).view(<span class="hljs-number">100</span>, <span class="hljs-number">-1</span>)</span><br><span class="line">y_train.shape</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([100, 1])
</code></pre><ul>
<li>이번에 Model을 nn.Module 추상 클래스를 상속 받아, class 형태로 모델링 해보겠습니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CubicModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = CubicModel()</span><br></pre></td></tr></table></figure>
<ul>
<li>train 시킬 때, loss 역시 nn.functional 에 있는 내장 mse loss 를 사용하여 보겠습니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">15000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = model(x_train)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># define loss</span></span><br><span class="line">    loss  = F.mse_loss(hypothesis, y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># Backprop &amp; update parameters</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1500</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch: 1500 -- loss 0.22306101024150848
epoch: 3000 -- loss 0.11560291796922684
epoch: 4500 -- loss 0.09848319739103317
epoch: 6000 -- loss 0.08879078179597855
epoch: 7500 -- loss 0.08104882389307022
epoch: 9000 -- loss 0.07452096790075302
epoch: 10500 -- loss 0.06889640539884567
epoch: 12000 -- loss 0.06398065388202667
epoch: 13500 -- loss 0.05964164435863495
epoch: 15000 -- loss 0.055785566568374634
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, model(x_train).data.numpy(), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_19_0.png" alt="png"></p>
<h2 id="3-Exponential-Regression-Model"><a href="#3-Exponential-Regression-Model" class="headerlink" title="3. Exponential Regression Model"></a>3. Exponential Regression Model</h2><p>$$<br>f(x) = e^{w_0x}<br>$$</p>
<p>$$<br>g(x) = \ln f(x) = w_0x<br>$$</p>
<ul>
<li>Exponential 의 경우, Linear Model 형태를 만들어 주기 위해, log 를 씌워 주워 train 을 시킨후, 다시 exponential 을 양변에 취해주는 형태로 modeling 을 하여야 한다.</li>
</ul>
<h3 id="3-1-Generate-Toy-data"><a href="#3-1-Generate-Toy-data" class="headerlink" title="3.1 Generate Toy data"></a>3.1 Generate Toy data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="hljs-number">20190505</span>)</span><br><span class="line">x = np.linspace(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">50</span>)</span><br><span class="line">y = np.exp(<span class="hljs-number">2</span> * x) + <span class="hljs-number">0.2</span> * (<span class="hljs-number">2</span> * np.random.rand(len(x)) - <span class="hljs-number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_23_0.png" alt="png"></p>
<h3 id="3-2-Define-Model"><a href="#3-2-Define-Model" class="headerlink" title="3.2 Define Model"></a>3.2 Define Model</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[xval, <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> xval <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor([np.log(y)]).view(<span class="hljs-number">50</span>, <span class="hljs-number">-1</span>)</span><br><span class="line">y_train.shape</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([50, 1])
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ExpModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure>
<ul>
<li>이번에는 optimize algorithm 중 Adam 을 사용해 보겠습니다.</li>
<li>Adam 은 adaptive 하게 learning rate 를 조정해 주는 algorithm 입니다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = ExpModel()</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">15000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = model(x_train)</span><br><span class="line">    </span><br><span class="line">    loss = F.mse_loss(hypothesis, y_train)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch: 1000 -- loss 1.4807509183883667
epoch: 2000 -- loss 0.6568859815597534
epoch: 3000 -- loss 0.2930431365966797
epoch: 4000 -- loss 0.1839657723903656
epoch: 5000 -- loss 0.1683545857667923
epoch: 6000 -- loss 0.16775406897068024
epoch: 7000 -- loss 0.16775156557559967
epoch: 8000 -- loss 0.16775153577327728
epoch: 9000 -- loss 0.16775155067443848
epoch: 10000 -- loss 0.16775155067443848
epoch: 11000 -- loss 0.16775155067443848
epoch: 12000 -- loss 0.16775155067443848
epoch: 13000 -- loss 0.16775153577327728
epoch: 14000 -- loss 0.1677515208721161
epoch: 15000 -- loss 0.1677515208721161
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, np.exp(model(x_train).data.numpy()), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_29_0.png" alt="png"></p>
<h2 id="4-Sine-amp-Cosine-Regression"><a href="#4-Sine-amp-Cosine-Regression" class="headerlink" title="4. Sine &amp; Cosine Regression"></a>4. Sine &amp; Cosine Regression</h2><p>$$<br>f(x) = w_0\cos(\pi x) + w_1\sin(\pi  x)<br>$$</p>
<h3 id="4-1-Generate-Toy-data"><a href="#4-1-Generate-Toy-data" class="headerlink" title="4.1 Generate Toy data"></a>4.1 Generate Toy data</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">100</span>)</span><br><span class="line">y = <span class="hljs-number">2</span> * np.cos(np.pi * x) + <span class="hljs-number">1.5</span> * np.sin(np.pi * x) + <span class="hljs-number">2</span> * np.random.rand(len(x)) - <span class="hljs-number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xlabel(<span class="hljs-string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">'y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_33_0.png" alt="png"></p>
<h3 id="4-2-Modeling"><a href="#4-2-Modeling" class="headerlink" title="4.2 Modeling"></a>4.2 Modeling</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[np.cos(np.pi*xval), np.sin(np.pi*xval), <span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> xval <span class="hljs-keyword">in</span> x])</span><br><span class="line">y_train = torch.FloatTensor(y).view(<span class="hljs-number">100</span>, <span class="hljs-number">-1</span>)</span><br><span class="line">y_train.shape</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([100, 1])
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SinCosModel</span><span class="hljs-params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self.linear(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = SinCosModel()</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    hypothesis = model(x_train)</span><br><span class="line">    </span><br><span class="line">    loss = F.mse_loss(hypothesis, y_train)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch: 1000 -- loss 1.1333037614822388
epoch: 2000 -- loss 0.45972707867622375
epoch: 3000 -- loss 0.36056602001190186
epoch: 4000 -- loss 0.3566252291202545
epoch: 5000 -- loss 0.3566077649593353
epoch: 6000 -- loss 0.3566077947616577
epoch: 7000 -- loss 0.3566077649593353
epoch: 8000 -- loss 0.3566077947616577
epoch: 9000 -- loss 0.3566077947616577
epoch: 10000 -- loss 0.3566077649593353
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">'train data'</span>)</span><br><span class="line">plt.plot(x, model(x_train).data.numpy(), <span class="hljs-string">'-r'</span>, linewidth=<span class="hljs-number">3</span>, label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_38_0.png" alt="png"></p>

        </div>
        
        
        
    </div>
</div>








    <div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-05-03T09:19:59.000Z">2019-05-03</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/MachineLearning/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 minutes read (About 853 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2019/05/03/Linear-Regression-with-Pytorch/">Linear Regression with Pytorch</a>
            
        </h1>
        <div class="content">
            <h1 id="Linear-Regression-through-Pytorch"><a href="#Linear-Regression-through-Pytorch" class="headerlink" title="Linear Regression through Pytorch"></a>Linear Regression through Pytorch</h1><ul>
<li>이번 포스트의 목적은 Linear Model을 Pytorch을 통해 구현해보며, 개인적으로 Pytorch의 사용을 연습하며 적응력을 높여보는 것입니다.</li>
</ul>
<h2 id="Import-Library"><a href="#Import-Library" class="headerlink" title="Import Library"></a>Import Library</h2><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="hljs-string">'retina'</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h2 id="Generate-Toy-Data"><a href="#Generate-Toy-Data" class="headerlink" title="Generate Toy Data"></a>Generate Toy Data</h2><p>$ y = \frac{1}{3} x + 5 $ 와 약간의 noise 를 합쳐 100 개의 toy data를 만들겠습니다.</p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Target Function</span></span><br><span class="line">f = <span class="hljs-keyword">lambda</span> x: <span class="hljs-number">1.0</span>/<span class="hljs-number">3.0</span> * x + <span class="hljs-number">5.0</span></span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="hljs-number">-40</span>, <span class="hljs-number">60</span>, <span class="hljs-number">100</span>)</span><br><span class="line">fx = f(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, fx)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_5_0.png" alt="png"></p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># y_train data with little noise</span></span><br><span class="line">y = fx + <span class="hljs-number">10</span> * np.random.rand(len(x))</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_6_0.png" alt="png"></p>
<h2 id="1-Gradient-Descent"><a href="#1-Gradient-Descent" class="headerlink" title="1. Gradient Descent"></a>1. Gradient Descent</h2><ol>
<li>Model (hypothesis) 를 설정합니다.<br>(여기선, Linear Regression 이므로, $y = Wx + b$ 형태를 사용합니다.)</li>
<li>Loss Function 을 정의합니다. (여기선, MSE loss 를 사용하겠습니다.)</li>
<li>gradient 를 계산합니다.<br>(여기선, Gradient Descent 방법으로 optimize 를 할 것이므로, optim.SGD() 를 사용합니다.)</li>
<li>parameter 를 update 합니다.</li>
</ol>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor(x)</span><br><span class="line">y_train = torch.FloatTensor(y)</span><br><span class="line">print(<span class="hljs-string">"x_train Tensor shape: "</span>, x_train.shape)</span><br><span class="line">print(<span class="hljs-string">"y_train Tensor shape: "</span>, y_train.shape)</span><br></pre></td></tr></table></figure>
<pre><code>x_train Tensor shape:  torch.Size([100])
y_train Tensor shape:  torch.Size([100])
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># train code</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># parameter setting &amp; initialize</span></span><br><span class="line">W = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line">b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># optimizer setting</span></span><br><span class="line">optimizer = optim.SGD([W, b], lr=<span class="hljs-number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># total epochs</span></span><br><span class="line">epochs = <span class="hljs-number">3000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    <span class="hljs-comment"># decide model(hypothesis)</span></span><br><span class="line">    model = W * x_train + b</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># loss function -&gt; MSE</span></span><br><span class="line">    loss = torch.mean((model - y_train)**<span class="hljs-number">2</span>)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-comment"># 10 epoch 마다 train loss 를 출력합니다.</span></span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">500</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, b.data, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch: 500 -- Parameters: W: tensor([0.3709]) b: tensor([5.6408]) -- loss 22.728315353393555
epoch: 1000 -- Parameters: W: tensor([0.3467]) b: tensor([7.9427]) -- loss 11.399767875671387
epoch: 1500 -- Parameters: W: tensor([0.3368]) b: tensor([8.8829]) -- loss 9.51008415222168
epoch: 2000 -- Parameters: W: tensor([0.3327]) b: tensor([9.2669]) -- loss 9.194862365722656
epoch: 2500 -- Parameters: W: tensor([0.3311]) b: tensor([9.4237]) -- loss 9.142287254333496
epoch: 3000 -- Parameters: W: tensor([0.3304]) b: tensor([9.4878]) -- loss 9.133516311645508
</code></pre><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">"train data"</span>)</span><br><span class="line">plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_10_0.png" alt="png"></p>
<h2 id="2-Stochastic-Gradient-Descent"><a href="#2-Stochastic-Gradient-Descent" class="headerlink" title="2. Stochastic Gradient Descent"></a>2. Stochastic Gradient Descent</h2><ol>
<li>Model (hypothesis) Setting</li>
<li>Loss Function Setting</li>
<li>최적화 알고리즘 선택</li>
<li>shuffle train data</li>
<li>mini-batch 마다 W, b 업데이트</li>
</ol>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># batch 를 generate 해주는 함수</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_batch</span><span class="hljs-params">(batch_size, x_train, y_train)</span>:</span></span><br><span class="line">    <span class="hljs-keyword">assert</span> len(x_train) == len(y_train)</span><br><span class="line">    result_batches = []</span><br><span class="line">    x_size = len(x_train)</span><br><span class="line">    </span><br><span class="line">    shuffled_id = np.arange(x_size)</span><br><span class="line">    np.random.shuffle(shuffled_id)</span><br><span class="line">    shuffled_x_train = x_train[shuffled_id]</span><br><span class="line">    shuffled_y_train = y_train[shuffled_id]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">for</span> start_idx <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, x_size, batch_size):</span><br><span class="line">        end_idx = start_idx + batch_size</span><br><span class="line">        batch = [shuffled_x_train[start_idx:end_idx], shuffled_y_train[start_idx:end_idx]]</span><br><span class="line">        result_batches.append(batch)</span><br><span class="line">    <span class="hljs-keyword">return</span> result_batches</span><br></pre></td></tr></table></figure>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># train</span></span><br><span class="line">W = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line">b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-keyword">True</span>)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD([W, b], lr=<span class="hljs-number">0.001</span>)</span><br><span class="line"></span><br><span class="line">epochs = <span class="hljs-number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):</span><br><span class="line">    <span class="hljs-keyword">for</span> x_batch, y_batch <span class="hljs-keyword">in</span> generate_batch(<span class="hljs-number">10</span>, x_train, y_train):</span><br><span class="line">        model = W * x_batch + b</span><br><span class="line">        loss = torch.mean((model - y_batch)**<span class="hljs-number">2</span>)</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">500</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        print(<span class="hljs-string">"epoch: &#123;&#125; -- Parameters: W: &#123;&#125; b: &#123;&#125; -- loss &#123;&#125;"</span>.format(epoch, W.data, b.data, loss.data))</span><br></pre></td></tr></table></figure>
<pre><code>epoch: 500 -- Parameters: W: tensor([0.0890]) b: tensor([9.5399]) -- loss 162.1055450439453
epoch: 1000 -- Parameters: W: tensor([0.3672]) b: tensor([9.5366]) -- loss 12.424881935119629
epoch: 1500 -- Parameters: W: tensor([0.3560]) b: tensor([9.5097]) -- loss 7.826609134674072
epoch: 2000 -- Parameters: W: tensor([0.3375]) b: tensor([9.5556]) -- loss 13.15934944152832
epoch: 2500 -- Parameters: W: tensor([0.2462]) b: tensor([9.5157]) -- loss 11.582895278930664
epoch: 3000 -- Parameters: W: tensor([0.3097]) b: tensor([9.5111]) -- loss 9.991677284240723
epoch: 3500 -- Parameters: W: tensor([0.2497]) b: tensor([9.5532]) -- loss 20.481367111206055
epoch: 4000 -- Parameters: W: tensor([0.4388]) b: tensor([9.5390]) -- loss 20.827198028564453
epoch: 4500 -- Parameters: W: tensor([0.1080]) b: tensor([9.4959]) -- loss 140.0277862548828
epoch: 5000 -- Parameters: W: tensor([0.3188]) b: tensor([9.4829]) -- loss 6.635367393493652
epoch: 5500 -- Parameters: W: tensor([0.2553]) b: tensor([9.5017]) -- loss 25.45773696899414
epoch: 6000 -- Parameters: W: tensor([0.2490]) b: tensor([9.5489]) -- loss 9.580666542053223
epoch: 6500 -- Parameters: W: tensor([0.3189]) b: tensor([9.5347]) -- loss 12.585128784179688
epoch: 7000 -- Parameters: W: tensor([0.3026]) b: tensor([9.4874]) -- loss 8.298829078674316
epoch: 7500 -- Parameters: W: tensor([0.3507]) b: tensor([9.6815]) -- loss 13.348054885864258
epoch: 8000 -- Parameters: W: tensor([0.1423]) b: tensor([9.5220]) -- loss 32.567440032958984
epoch: 8500 -- Parameters: W: tensor([0.7147]) b: tensor([9.5182]) -- loss 75.97190856933594
epoch: 9000 -- Parameters: W: tensor([0.5170]) b: tensor([9.5289]) -- loss 39.07848358154297
epoch: 9500 -- Parameters: W: tensor([0.3748]) b: tensor([9.5590]) -- loss 10.358983993530273
epoch: 10000 -- Parameters: W: tensor([0.2958]) b: tensor([9.6088]) -- loss 7.410649299621582
</code></pre><ul>
<li>Stochasitic 하게 loss의 gradient 를 계산하여, parameter update를 하므로, loss 가 굉장히 oscilation 이 나타나며 감소하는 것을 볼 수 있다.</li>
</ul>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y, <span class="hljs-string">'o'</span>, label=<span class="hljs-string">"train data"</span>)</span><br><span class="line">plt.plot(x_train.data.numpy(), W.data.numpy()*x + b.data.numpy(), label=<span class="hljs-string">'fitted'</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="output_15_0.png" alt="png"></p>
<figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

        </div>
        
        
        
    </div>
</div>








</div>
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered">
                <div>
                    
                        <img class="image is-128x128 has-mb-6" src="/images/profile.jpeg" alt="Emjay Ahn">
                    
                    
                    <p class="is-size-4 is-block">
                        Emjay Ahn
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        data scientist
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Seoul, Korea</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <p class="title has-text-weight-normal">
                        71
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <p class="title has-text-weight-normal">
                        20
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <p class="title has-text-weight-normal">
                        14
                    </p>
                </div>
            </div>
        </nav>
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/emjayahn" target="_blank">
                Follow</a>
        </div>
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Github" href="https://github.com/emjayahn">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Facebook" href="https://facebook.com/jjminjae">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="RSS" href="/atom.xml">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        

<div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Links
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://hexo.io" target="_blank">
                    <span class="level-left">
                        <span class="level-item">Hexo</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">hexo.io</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://github.com/ppoffice" target="_blank">
                    <span class="level-left">
                        <span class="level-item">PPOffice</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>


    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/DataStructure/">
            <span class="level-start">
                <span class="level-item">DataStructure</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Diary/">
            <span class="level-start">
                <span class="level-item">Diary</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">42</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Google-Cloud-Platform/">
            <span class="level-start">
                <span class="level-item">Google Cloud Platform</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Lecture/">
            <span class="level-start">
                <span class="level-item">Lecture</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Lecture/CS231n/">
            <span class="level-start">
                <span class="level-item">CS231n</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Lecture/딥러닝을-이용한-자연어-처리/">
            <span class="level-start">
                <span class="level-item">딥러닝을 이용한 자연어 처리</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/MachineLearning/">
            <span class="level-start">
                <span class="level-item">MachineLearning</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/MachineLearning/Apache-Spark/">
            <span class="level-start">
                <span class="level-item">Apache Spark</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/MachineLearning/Pytorch/">
            <span class="level-start">
                <span class="level-item">Pytorch</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Math/">
            <span class="level-start">
                <span class="level-item">Math</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/">
            <span class="level-start">
                <span class="level-item">wiki</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">10</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/wiki/MySQL/">
            <span class="level-start">
                <span class="level-item">MySQL</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/NGINX/">
            <span class="level-start">
                <span class="level-item">NGINX</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/Pillow/">
            <span class="level-start">
                <span class="level-item">Pillow</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/Provision/">
            <span class="level-start">
                <span class="level-item">Provision</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/Python/">
            <span class="level-start">
                <span class="level-item">Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/Requests/">
            <span class="level-start">
                <span class="level-item">Requests</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/Scrapy/">
            <span class="level-start">
                <span class="level-item">Scrapy</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/Selenium/">
            <span class="level-start">
                <span class="level-item">Selenium</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/wiki/Xpath/">
            <span class="level-start">
                <span class="level-item">Xpath</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li>
            </ul>
        </div>
    </div>
</div>
    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/CS231n/" style="font-size: 15px;">CS231n</a> <a href="/tags/Classification-확률론적생성모형-Generative-생성모형-분류모델/" style="font-size: 10px;">Classification, 확률론적생성모형, Generative, 생성모형, 분류모델</a> <a href="/tags/Crawling-Web-Requests/" style="font-size: 10px;">Crawling, Web, Requests</a> <a href="/tags/Google-Cloud-Platform/" style="font-size: 10px;">Google Cloud Platform</a> <a href="/tags/TWIL/" style="font-size: 20px;">TWIL</a> <a href="/tags/Thread/" style="font-size: 10px;">Thread</a> <a href="/tags/datastructure/" style="font-size: 10px;">datastructure</a> <a href="/tags/datastructure-stack/" style="font-size: 10px;">datastructure, stack</a> <a href="/tags/mysql-MYSQL-database/" style="font-size: 10px;">mysql, MYSQL, database</a> <a href="/tags/nginx-proxy/" style="font-size: 10px;">nginx, proxy</a> <a href="/tags/pillow-Pillow-image/" style="font-size: 10px;">pillow, Pillow, image</a> <a href="/tags/scrapy-crawling-web/" style="font-size: 10px;">scrapy, crawling, web</a> <a href="/tags/summary/" style="font-size: 15px;">summary</a> <a href="/tags/자동화-selenium-webdriver/" style="font-size: 10px;">자동화, selenium, webdriver</a>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2019/06/17/gcp-setting/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="[GCP] Computing Engine 환경설정">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-17T11:54:01.000Z">2019-06-17</time></div>
                    <a href="/2019/06/17/gcp-setting/" class="has-link-black-ter is-size-6">[GCP] Computing Engine 환경설정</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Google-Cloud-Platform/">Google Cloud Platform</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/06/03/Classification-Metrics/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Classification Metrics">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-06-03T03:18:57.000Z">2019-06-03</time></div>
                    <a href="/2019/06/03/Classification-Metrics/" class="has-link-black-ter is-size-6">Classification Metrics</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/05/31/SPARK-BASIC-1/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="SPARK BASIC 1">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-05-31T12:07:52.000Z">2019-05-31</time></div>
                    <a href="/2019/05/31/SPARK-BASIC-1/" class="has-link-black-ter is-size-6">SPARK BASIC 1</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a> / <a class="has-link-grey -link" href="/categories/MachineLearning/Apache-Spark/">Apache Spark</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/05/20/CS231n-Lecture05-Summary/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="[CS231n]Lecture05-CNN">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-05-20T08:36:09.000Z">2019-05-20</time></div>
                    <a href="/2019/05/20/CS231n-Lecture05-Summary/" class="has-link-black-ter is-size-6">[CS231n]Lecture05-CNN</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Lecture/">Lecture</a> / <a class="has-link-grey -link" href="/categories/Lecture/CS231n/">CS231n</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/05/18/CS231n-Lecture04-Summary/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="[CS231n]Lecture04-Backprop/NeuralNetworks">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-05-18T14:21:08.000Z">2019-05-18</time></div>
                    <a href="/2019/05/18/CS231n-Lecture04-Summary/" class="has-link-black-ter is-size-6">[CS231n]Lecture04-Backprop/NeuralNetworks</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Lecture/">Lecture</a> / <a class="has-link-grey -link" href="/categories/Lecture/CS231n/">CS231n</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>

    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2019/06/">
                <span class="level-start">
                    <span class="level-item">June 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/05/">
                <span class="level-start">
                    <span class="level-item">May 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">9</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/01/">
                <span class="level-start">
                    <span class="level-item">January 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/12/">
                <span class="level-start">
                    <span class="level-item">December 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/11/">
                <span class="level-start">
                    <span class="level-item">November 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">25</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2018/10/">
                <span class="level-start">
                    <span class="level-item">October 2018</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">20</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
        </div>
    
</div>

                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/Emjaybloglogo_edit.png" alt="Emjay&#39;s DailyBlog" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 EmjayAhn(Minjae Ahn)&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Download on GitHub" href="https://github.com/emjayahn/">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
    <script src="/js/gallery.js" defer></script>
    

    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>

    
    

<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    

    
    
    
    

    
    
    
    
    
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>
    <script src="/js/clipboard.js" defer></script>
    

    
    
    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css"><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
    
</body>
</html>